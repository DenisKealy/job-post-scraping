{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Post Scraping\n",
    "\n",
    "In this notebook we are going to scrape the job listings for 'Data Analyst' from an Egyptian website called Wuzzuf then extract the information from the listings and store the results in a csv file.\n",
    "\n",
    "## Website\n",
    "\n",
    "<img src=\"./img/website.png\" alt=\"WUZZUF website\" width=\"800\"/>\n",
    "\n",
    "## Data Objectives\n",
    "\n",
    "Each listing result must contain - \n",
    " - Date\n",
    " - Job Title\n",
    " - Company Name\n",
    " - Company Address\n",
    " - Full-time/Part-time\n",
    " - Career Level\n",
    " - URL\n",
    "\n",
    "Aditionally we will attempt to extract the following information - \n",
    " - Job Description\n",
    " - Job Requirements\n",
    " - Salary\n",
    " - Required Experience \n",
    " - Required Education\n",
    " - Skills/Tools\n",
    "\n",
    "\n",
    " ## Job Description\n",
    "\n",
    "This job description was listed on a freelancing website:\n",
    "\n",
    "> The project goal is to write Python Script to Scrape All Data Analyst Jobs data Posted on Wuzzuf Website Using BeautifulSoup\n",
    ">\n",
    "> - I was able to Extract the Job Title, Company Name, Company Address, Job Time, Job Level, Job Link and The period in which the job was posted which is converted to the Post Date and Put all of them in a Spreadsheet\n",
    ">\n",
    "> Website - https://wuzzuf.net/search/jobs/?a=navbl%7Cspbl&q=data%20analyst&start=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Parameters\n",
    "\n",
    "Here are some parameters that can change the output of the notebook:\n",
    "\n",
    " - `NUM_PAGES` -> This sets the number of pages to scrape from the search results (15 job posts per page, default = 3)\n",
    " - `SEARCH_TERM` -> This sets the search term (default = 'data analyst')\n",
    "\n",
    "The following parameter shouldn't be changed as this notebook is setup specifically to parse WUZZUF search results:\n",
    " - `BASE_URL` -> This is the base URL, used to follow relative URL links during the scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PAGES = 3 # 15 jobs per page\n",
    "SEARCH_TERM = 'data analyst' \n",
    "BASE_URL = 'https://wuzzuf.net'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We are using `requests` and `BeautifulSoup` to request and parse the html, respectively. We are using `datetime` to parse dates into timestamps.  `urllib` is used to safely process URLs. `re` and `json` are used to parse and navigate the JSON data from the webpage as this page is dynamically loaded, meaning the static HTML doesn't yield the information we are looking to extract. Finally, `pandas` is used to export the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import urllib.parse\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_page_urls(pages, search_term):\n",
    "    '''Builds the URLs to retrieve our job posts based on the number of pages requested'''\n",
    "    url = (f'https://wuzzuf.net/search/jobs/?a=navbl%7Cspbl&q={urllib.parse.quote(search_term)}&start=')\n",
    "    urls = list()\n",
    "    for i in range(pages):\n",
    "        urls.append(url + str(i))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_occurrence(n, c, s):\n",
    "    '''Find the nth occurnace (0-indexed) of character c in string s'''\n",
    "    nth = -1\n",
    "    for i in range(0, n):\n",
    "        nth = s.find(c, nth + 1)\n",
    "    return nth\n",
    "\n",
    "### Function Testing ###\n",
    "assert nth_occurrence(1, 'F', 'Fail') == 0, f'Should equal 0, got {nth_occurrence(1, \"F\", \"Fail\")}'\n",
    "assert nth_occurrence(2, 't', 'test') == 3, f'Should equal 3, got {nth_occurrence(2, \"t\", \"test\")}'\n",
    "assert nth_occurrence(5, '.', '.....') == 4, f'Should equal 4, got {nth_occurrence(1, \"F\", \"Fail\")}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_urls(page_url):\n",
    "    '''Extracts the individual job listings from a search result page'''\n",
    "    post_urls = list()\n",
    "    html = requests.get(page_url)\n",
    "    soup = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "    # Debug HTML\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    potential_links = soup.find_all('a')\n",
    "    for link in potential_links:\n",
    "        url = link.get('href')\n",
    "        if url is not None:\n",
    "            if url.__contains__('/jobs/') and not url.__contains__('http'):\n",
    "                post_urls.append(BASE_URL + urllib.parse.quote(url))\n",
    "    return post_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_post(post_url):\n",
    "    '''Extracts the Job Details from a Job Post URL'''\n",
    "    post = dict()\n",
    "    html = requests.get(post_url)\n",
    "    soup = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "    # Debug HTML\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    # Find script tag\n",
    "    script_tag = soup.find(\"script\")\n",
    "\n",
    "    # Find json Data - begin at third curly brace\n",
    "    third_bracket = nth_occurrence(3, '{', script_tag.text)\n",
    "\n",
    "    # Find the 4th last semi colon\n",
    "    reversed = script_tag.text[::-1]\n",
    "    sc = nth_occurrence(4, ';', reversed)\n",
    "    sc = len(reversed) - sc - 1\n",
    "\n",
    "    # Trim and load json\n",
    "    trimmed_string = script_tag.text[third_bracket:sc]\n",
    "\n",
    "    # Debug JSON\n",
    "    # print(trimmed_string)\n",
    "\n",
    "    data = json.loads(trimmed_string)\n",
    "\n",
    "    # Find job ID, company ID and Job details\n",
    "    job_json = str(data[\"entities\"][\"applicationStatistics\"][\"collection\"])\n",
    "    job_id = job_json[2:job_json.find(':')-1]\n",
    "    job_details = data[\"entities\"][\"job\"][\"collection\"][job_id][\"attributes\"]\n",
    "    if data[\"entities\"][\"job\"][\"collection\"][job_id][\"relationships\"][\"company\"][\"data\"] is not None:\n",
    "        company_id = data[\"entities\"][\"job\"][\"collection\"][job_id][\"relationships\"][\"company\"][\"data\"][\"id\"]\n",
    "    else:\n",
    "        company_id = None\n",
    "\n",
    "    # Date\n",
    "    post['Date'] = datetime.strptime(\n",
    "        job_details['postedAt'], '%m\\u002F%d\\u002F%Y %H:%M:%S')\n",
    "\n",
    "    # Job Title\n",
    "    post['Job Title'] = job_details['title']\n",
    "\n",
    "    # Company Name\n",
    "    if company_id is not None:\n",
    "        post['Company Name'] = data[\"entities\"][\"company\"][\"collection\"][company_id][\"attributes\"][\"name\"]\n",
    "    else:\n",
    "        post['Company Name'] = 'Confidential'\n",
    "\n",
    "    # Company Address\n",
    "    address = \"\"\n",
    "    if job_details[\"location\"][\"area\"] is not None:\n",
    "        address = job_details[\"location\"][\"area\"][\"name\"]\n",
    "    if job_details[\"location\"][\"city\"] is not None:\n",
    "        if address != \"\":\n",
    "            address += ', ' + job_details[\"location\"][\"city\"][\"name\"]\n",
    "        else:\n",
    "            address = job_details[\"location\"][\"city\"][\"name\"]\n",
    "    if job_details[\"location\"][\"country\"] is not None:\n",
    "        if address != \"\":\n",
    "            address += ', ' + job_details[\"location\"][\"country\"][\"name\"]\n",
    "        else:\n",
    "            address = job_details[\"location\"][\"country\"][\"name\"]\n",
    "    post['Company Address'] = address\n",
    "\n",
    "    # Work Type\n",
    "    first_pass = True\n",
    "    for work_type in job_details[\"workTypes\"]:\n",
    "        if first_pass:\n",
    "            work_types = work_type[\"displayedName\"]\n",
    "            first_pass = False\n",
    "        else:\n",
    "            work_types += ', ' + work_type[\"displayedName\"]\n",
    "    post['Work Type'] = work_types\n",
    "\n",
    "    # Career Level\n",
    "    career_level = \"\"\n",
    "    if job_details[\"careerLevel\"][\"name\"] is not None:\n",
    "        career_level = job_details[\"careerLevel\"][\"name\"]\n",
    "    if job_details[\"careerLevel\"][\"hint\"] is not None:\n",
    "        career_level += ' (' + job_details[\"careerLevel\"][\"hint\"] + ')'\n",
    "\n",
    "    post['Career Level'] = career_level\n",
    "\n",
    "    # URL\n",
    "    post['URL'] = post_url\n",
    "\n",
    "    # Job Description\n",
    "    post['Description'] = job_details['description'].replace('\\n', \"\")\n",
    "\n",
    "    # Job Requirements\n",
    "    post['Requirements'] = job_details['requirements'].replace('\\n', \"\")\n",
    "\n",
    "    # Salary\n",
    "    if job_details['salary']['isPaid'] is True:\n",
    "        if job_details['salary']['min'] is None and job_details['salary']['max'] is None:\n",
    "            salary = \"Confidential\"\n",
    "        elif job_details['salary']['min'] is not None and job_details['salary']['max'] is not None:\n",
    "            salary = str(job_details['salary']['min']) + \\\n",
    "                ' - ' + str(job_details['salary']['max'])\n",
    "        elif job_details['salary']['min'] is not None or job_details['salary']['max'] is not None:\n",
    "            salary = job_details['salary']['min'] or job_details['salary']['max']\n",
    "        if job_details['salary']['currency'] is not None:\n",
    "            salary += \" \" + job_details['salary']['currency']['code']\n",
    "        if job_details['salary']['period'] is not None:\n",
    "            salary += \" (\" + job_details['salary']['period']['name'] + ')'\n",
    "    else:\n",
    "        salary = \"Unpaid\"\n",
    "\n",
    "    if job_details['salary']['additionalDetails'] is not None:\n",
    "        salary += ', ' + job_details['salary']['additionalDetails']\n",
    "    post['Salary'] = salary\n",
    "\n",
    "    # Required Experience\n",
    "    experience = \"\"\n",
    "    if job_details['workExperienceYears']['min'] is None and job_details['workExperienceYears']['max'] is None:\n",
    "        experience = \"Unspecified\"\n",
    "    elif job_details['workExperienceYears']['min'] is not None and job_details['workExperienceYears']['max'] is not None:\n",
    "        experience = str(job_details['workExperienceYears']['min']) + \\\n",
    "            ' - ' + str(job_details['workExperienceYears']['max']) + ' years'\n",
    "    elif job_details['workExperienceYears']['min'] is not None and job_details['workExperienceYears']['max'] is None:\n",
    "        experience = str(job_details['workExperienceYears']['min']) + '+ years'\n",
    "    else:\n",
    "        experience = '0 - ' + \\\n",
    "            str(job_details['workExperienceYears']['max']) + ' years'\n",
    "\n",
    "    post['Experience'] = experience\n",
    "\n",
    "    # Required Education\n",
    "    post['Education'] = job_details['candidatePreferences']['educationLevel']['name']\n",
    "\n",
    "    # Skills/Tools\n",
    "    skills = \"\"\n",
    "    first_pass = True\n",
    "    for entry in job_details['keywords']:\n",
    "        if first_pass:\n",
    "            skills = entry['name']\n",
    "            first_pass = False\n",
    "        else:\n",
    "            skills += \", \" + entry['name']\n",
    "    post['Skills & Tools'] = skills\n",
    "\n",
    "    return post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(pages, search_term):\n",
    "    '''Scrapes all the search results based on the search term and number of '''\n",
    "    page_urls = build_page_urls(pages, search_term)\n",
    "    post_urls = list()\n",
    "    posts = list()\n",
    "    for page in page_urls:\n",
    "        post_urls.append(get_post_urls(page))\n",
    "    for page in post_urls:\n",
    "        for url in page:\n",
    "            print(f'Scraping URL => {url}')\n",
    "            result = scrape_post(url)\n",
    "            posts.append(result)\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Website\n",
    "\n",
    "To alter the output you can change the parameters at the top of the notebook (in the first code cell)\n",
    "\n",
    " - `NUM_PAGES` -> This sets the number of pages to scrape from the search results (15 job posts per page, default = 3)\n",
    " - `SEARCH_TERM` -> This sets the search term for the scraping process (default = 'data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL => https://wuzzuf.net/jobs/p/9rPTWJnYPFuq-Professional-Data-Analyst-Cairo-Egypt%3Fo%3D1%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/lGTaAJcRIwbm-Data-Analyst-Gomla-Market-Alexandria-Egypt%3Fo%3D2%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/R7KdIv7dCm0z-Senior-Data-Analyst---Cairo-Cairo-Egypt%3Fo%3D3%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/TWguALrIS6vT-Senior-Data-Analyst-Alarabia-Group-Cairo-Egypt%3Fo%3D4%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/9AAaTU2msaG5-Data-Analyst-Hands-of-Hope-Physical-Therapy-Wellness-Cairo-Egypt%3Fo%3D5%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/adeG14H7rqQA-Data-Analyst-Gila-Electric-Cairo-Egypt%3Fo%3D6%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/kTeqVGENBIjl-Senior-Business-Intelligence-Analyst-Future-Group-Giza-Egypt%3Fo%3D7%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/123dzktUWSha-Data-Analyst-Lecico-Egypt-Alexandria-Egypt%3Fo%3D8%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/1dM41TI8bc8w-Business-System-Analyst-The-Food-Lab-Cairo-Egypt%3Fo%3D9%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/WRQiBG8UhUZb-Financial-Analyst-Allamna-Integrated-Solutions-Cairo-Egypt%3Fo%3D10%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/38nEwo6G6675-Sales-Analyst-Giza-Egypt%3Fo%3D11%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/KkOIsznkgJxQ-Senior-Financial-Analyst-Future-Group-Giza-Egypt%3Fo%3D12%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/Nmz0uUUQFbbI-Chargeback-Analyst-WebBeds-Cairo-Egypt%3Fo%3D13%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/hp32WHc5otxr-Senior-Treasury-Analyst-TAQA-Petroleum-Cairo-Egypt%3Fo%3D14%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/SmiRP57Qnyx1-Data-Analyst---Quality-Assurance-Department-IdealRatings-Cairo-Egypt%3Fo%3D15%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/LjehaQu2c9ZJ-HR-Reporting-Analyst-Partner-More-Giza-Egypt%3Fo%3D16%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/ecDQZn7zPGxQ-Senior-Data-Analyst-Z2-Data-Cairo-Egypt%3Fo%3D17%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/8YOY92FomUao-Business-Analyst-Cilantro-Cairo-Egypt%3Fo%3D18%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/5JCxxhUwHrzn-Data-Analyst---Banha-Z2-Data-Qalubia-Egypt%3Fo%3D19%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/r23QlbZLj34c-Senior-Financial-Data-Analyst-Z2-Data-Cairo-Egypt%3Fo%3D20%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/JeFJXhJWDb4O-Junior-Financial-Data-Analyst-Z2-Data-Cairo-Egypt%3Fo%3D21%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/mfezdURGilqD-Senior-Research-Analyst---Mobile-Phones-IDC-Cairo-Egypt%3Fo%3D22%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/vRmBDfFqeBXN-Junior-Data-Analyst-Z2-Data-Cairo-Egypt%3Fo%3D23%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/Jn0hHELYsTGk-Senior-Software-Business-Analyst-Softec-Technologies-Cairo-Egypt%3Fo%3D24%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/sNUUFKB219oN-Junior-Analyst-Synergy-Markets-Cairo-Egypt%3Fo%3D25%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/QclH1KOocgVK-Product-Analyst-Unifonic-Cairo-Egypt%3Fo%3D26%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/3ZTNoLhqBc6T-Data-Analyst-Arma-Foods-Cairo-Egypt%3Fo%3D27%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/khwBfk200wi9-Financial-Analyst-Cairo-Egypt%3Fo%3D28%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/8NTbc88fpIpa-Customer-Insights-Analyst-CVM-Proposition-Analyst-Etisalat-Egypt-Cairo-Egypt%3Fo%3D29%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/aDcFscot81o2-Business-Research-Analyst---German-Speaker-Infomineo-Cairo-Egypt%3Fo%3D30%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/vJjm5jLTqfmR-Business-Analyst-Target-Recruitment-HR-Solutions-Cairo-Egypt%3Fo%3D31%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/TyuOp04PIr0f-Senior-Business-Analyst-Easy-Cash-Cairo-Egypt%3Fo%3D32%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/QULmM8c1vDma-Senior-RD-Analyst--Banha-Z2-Data-Qalubia-Egypt%3Fo%3D33%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/L9rruA4pqmgY-Financial-Analyst-Multinational-Organization-Giza-Egypt%3Fo%3D34%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/anwQfniZEZkK-Cash-Flow-Analyst-The-International-School-of-Elite-Education-Cairo-Egypt%3Fo%3D35%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/hsP8ln1roOo5-Sales-Operations-Analyst-Target-for-Chemicals-industry-and-trade-Alexandria-Egypt%3Fo%3D36%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/krdZl1GdrxAP-Tech-Lead-and-System-Analyst-Dafa-Giza-Egypt%3Fo%3D37%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/n9sIpP20YRDL-Financial-EditorAnalyst-Argaam-Giza-Egypt%3Fo%3D38%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/zR4AJAwx21Y7-Issuing-Fraud-Monitoring-Senior-Analyst-Network-International--Egypt-Cairo-Egypt%3Fo%3D39%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/Cm1GiRcWcBec-System-Analyst-Simple-Way-Digital-Solution-Cairo-Egypt%3Fo%3D40%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/jzNIjX873nvy-E-Commerce-Marketing-Data-Analyst-Cairo-Egypt%3Fo%3D41%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/83qlVEErGjOy-Market-Research-Analyst-Guardian-Glass-Sharqia-Egypt%3Fo%3D42%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/TQ24hQOL7LKM-Senior-Business-Analyst-United-Media-Services-Cairo-Egypt%3Fo%3D43%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/3gKxwLEn2AQf-Data-Analyst-GPS-Cairo-Egypt%3Fo%3D44%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n",
      "Scraping URL => https://wuzzuf.net/jobs/p/G3ClSnfviwMN-Research-Analyst-El-Nour-trading-Giza-Egypt%3Fo%3D45%26l%3Dsp%26t%3Dsj%26a%3Ddata%20analyst%7Csearch-v3%7Cnavbl%7Cspbl\n"
     ]
    }
   ],
   "source": [
    "results = scrape_website(NUM_PAGES, SEARCH_TERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Address</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Career Level</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Education</th>\n",
       "      <th>Skills &amp; Tools</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-04 15:19:10</td>\n",
       "      <td>Professional Data Analyst</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Cairo, Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Experienced (Non-Manager)</td>\n",
       "      <td>https://wuzzuf.net/jobs/p/9rPTWJnYPFuq-Profess...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Senior Data Analytics, Business Int...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Visualization.&lt;/li&gt;&lt;li&gt;Master Data Man...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>7+ years</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Analytics, BI, Data Analysis, Data Governance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-25 09:36:20</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gomla Market</td>\n",
       "      <td>Ameria, Alexandria, Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry Level (Junior Level / Fresh Grad)</td>\n",
       "      <td>https://wuzzuf.net/jobs/p/lGTaAJcRIwbm-Data-An...</td>\n",
       "      <td>&lt;p&gt;At &lt;strong&gt;Gomla Market&lt;/strong&gt;, we deal w...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Bachelor's or Master's degree in Stati...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1 - 2 years</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Analysis, SAS, SPSS, SQL, Statistics, Data Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-18 16:24:40</td>\n",
       "      <td>Senior Data Analyst - Cairo</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Cairo, Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Experienced (Non-Manager)</td>\n",
       "      <td>https://wuzzuf.net/jobs/p/R7KdIv7dCm0z-Senior-...</td>\n",
       "      <td>&lt;p&gt;Egybell is hiring RSC Analytic Manager for ...</td>\n",
       "      <td>&lt;p&gt;Additional Requirements:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;1. To h...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>5 - 9 years</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Data, Google Analytics, Marketing, Management,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-18 11:32:23</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Alarabia Group</td>\n",
       "      <td>10th of Ramadan City, Cairo, Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Experienced (Non-Manager)</td>\n",
       "      <td>https://wuzzuf.net/jobs/p/TWguALrIS6vT-Senior-...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;To understand business requirements in...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;BSc/BA in Computer Science or relevant...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>2 - 5 years</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>BI, BI Developer, Computer Science, developer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-07 21:44:59</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hands of Hope Physical Therapy &amp; Wellness</td>\n",
       "      <td>Maadi, Cairo, Egypt</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Experienced (Non-Manager)</td>\n",
       "      <td>https://wuzzuf.net/jobs/p/9AAaTU2msaG5-Data-An...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Track, collect, and interpret data, th...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Essential experience in one or more of...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>3 - 18 years</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Analysis, Analyst, Data, Data Analysis, Data A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date                    Job Title  \\\n",
       "0 2022-10-04 15:19:10    Professional Data Analyst   \n",
       "1 2022-09-25 09:36:20                 Data Analyst   \n",
       "2 2022-09-18 16:24:40  Senior Data Analyst - Cairo   \n",
       "3 2022-09-18 11:32:23          Senior Data Analyst   \n",
       "4 2022-09-07 21:44:59                 Data Analyst   \n",
       "\n",
       "                                Company Name  \\\n",
       "0                               Confidential   \n",
       "1                               Gomla Market   \n",
       "2                               Confidential   \n",
       "3                             Alarabia Group   \n",
       "4  Hands of Hope Physical Therapy & Wellness   \n",
       "\n",
       "                      Company Address  Work Type  \\\n",
       "0                        Cairo, Egypt  Full Time   \n",
       "1           Ameria, Alexandria, Egypt  Full Time   \n",
       "2                        Cairo, Egypt  Full Time   \n",
       "3  10th of Ramadan City, Cairo, Egypt  Full Time   \n",
       "4                 Maadi, Cairo, Egypt  Full Time   \n",
       "\n",
       "                              Career Level  \\\n",
       "0                Experienced (Non-Manager)   \n",
       "1  Entry Level (Junior Level / Fresh Grad)   \n",
       "2                Experienced (Non-Manager)   \n",
       "3                Experienced (Non-Manager)   \n",
       "4                Experienced (Non-Manager)   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://wuzzuf.net/jobs/p/9rPTWJnYPFuq-Profess...   \n",
       "1  https://wuzzuf.net/jobs/p/lGTaAJcRIwbm-Data-An...   \n",
       "2  https://wuzzuf.net/jobs/p/R7KdIv7dCm0z-Senior-...   \n",
       "3  https://wuzzuf.net/jobs/p/TWguALrIS6vT-Senior-...   \n",
       "4  https://wuzzuf.net/jobs/p/9AAaTU2msaG5-Data-An...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  <p><strong>Senior Data Analytics, Business Int...   \n",
       "1  <p>At <strong>Gomla Market</strong>, we deal w...   \n",
       "2  <p>Egybell is hiring RSC Analytic Manager for ...   \n",
       "3  <ul><li>To understand business requirements in...   \n",
       "4  <ul><li>Track, collect, and interpret data, th...   \n",
       "\n",
       "                                        Requirements        Salary  \\\n",
       "0  <ul><li>Visualization.</li><li>Master Data Man...  Confidential   \n",
       "1  <ul><li>Bachelor's or Master's degree in Stati...  Confidential   \n",
       "2  <p>Additional Requirements:</p><ul><li>1. To h...  Confidential   \n",
       "3  <ul><li>BSc/BA in Computer Science or relevant...  Confidential   \n",
       "4  <ul><li>Essential experience in one or more of...  Confidential   \n",
       "\n",
       "     Experience          Education  \\\n",
       "0      7+ years  Bachelor's Degree   \n",
       "1   1 - 2 years  Bachelor's Degree   \n",
       "2   5 - 9 years  Bachelor's Degree   \n",
       "3   2 - 5 years  Bachelor's Degree   \n",
       "4  3 - 18 years  Bachelor's Degree   \n",
       "\n",
       "                                      Skills & Tools  \n",
       "0  Analytics, BI, Data Analysis, Data Governance,...  \n",
       "1  Analysis, SAS, SPSS, SQL, Statistics, Data Ana...  \n",
       "2  Data, Google Analytics, Marketing, Management,...  \n",
       "3  BI, BI Developer, Computer Science, developer,...  \n",
       "4  Analysis, Analyst, Data, Data Analysis, Data A...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_string = str(int(datetime.timestamp(datetime.now())))\n",
    "df.to_csv(path_or_buf=f'outputs/WUZZUF_{SEARCH_TERM}_{timestamp_string}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('web-scraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9a7d948b703bc7eaf693fa5a4315067dde8a1dcc0809ad0f7482a5f4a995ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
